{
 "metadata": {
  "name": "",
  "signature": "sha256:6f8317351078bf212342126d708ebf26645b5e541dbabe104aa405bafab6b1db"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# DAT_SF_13 Midterm Homework 4\n",
      "\n",
      "###About the data\n",
      "For this midterm, you'll be working with a dataset related to classifying emails as spam. The dataset was built by researchers at the UCI Machine Learning Institute. The following link is for reference only; the spam dataset is included in our github repo, in the HW4 directory. _Be sure to use the dataset provided in our course github repo._\n",
      "\n",
      "http://archive.ics.uci.edu/ml/datasets/Spambase\n",
      "\n",
      "**Data Set Information:**\n",
      "\n",
      "The \"spam\" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography...\n",
      "\n",
      "**Attribute Information:**\n",
      "\n",
      "The last column of 'spambase.data' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail. The run-length attributes (55-57) measure the length of sequences of consecutive capital letters."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Definitions of the attributes:\n",
      "\n",
      "**48 continuous real [0,100] attributes of type word_freq_WORD**\n",
      "\n",
      "= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail. A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.\n",
      "\n",
      "**6 continuous real [0,100] attributes of type char_freq_CHAR**\n",
      "\n",
      "= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
      "\n",
      "**1 continuous real [1,...] attribute of type capital_run_length_average**\n",
      "\n",
      "= average length of uninterrupted sequences of capital letters\n",
      "\n",
      "**1 continuous integer [1,...] attribute of type capital_run_length_longest**\n",
      "\n",
      "= length of longest uninterrupted sequence of capital letters\n",
      "\n",
      "**1 continuous integer [1,...] attribute of type capital_run_length_total**\n",
      "\n",
      "= sum of length of uninterrupted sequences of capital letters = total number of capital letters in the e-mail\n",
      "\n",
      "**1 nominal {0,1} class attribute of type spam**\n",
      "\n",
      "= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "pd.set_option('display.max_rows',100)\n",
      "pd.set_option('display.max_columns',60)\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the spambase.csv as a pandas DataFrame (last column of data contains Target Data - is_spam)\n",
      "spam_data = pd.read_csv(\"spambase.csv\")\n",
      "spam_data.describe()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>word_freq_make</th>\n",
        "      <th>word_freq_address</th>\n",
        "      <th>word_freq_all</th>\n",
        "      <th>word_freq_3d</th>\n",
        "      <th>word_freq_our</th>\n",
        "      <th>word_freq_over</th>\n",
        "      <th>word_freq_remove</th>\n",
        "      <th>word_freq_internet</th>\n",
        "      <th>word_freq_order</th>\n",
        "      <th>word_freq_mail</th>\n",
        "      <th>word_freq_receive</th>\n",
        "      <th>word_freq_will</th>\n",
        "      <th>word_freq_people</th>\n",
        "      <th>word_freq_report</th>\n",
        "      <th>word_freq_addresses</th>\n",
        "      <th>word_freq_free</th>\n",
        "      <th>word_freq_business</th>\n",
        "      <th>word_freq_email</th>\n",
        "      <th>word_freq_you</th>\n",
        "      <th>word_freq_credit</th>\n",
        "      <th>word_freq_your</th>\n",
        "      <th>word_freq_font</th>\n",
        "      <th>word_freq_000</th>\n",
        "      <th>word_freq_money</th>\n",
        "      <th>word_freq_hp</th>\n",
        "      <th>word_freq_hpl</th>\n",
        "      <th>word_freq_george</th>\n",
        "      <th>word_freq_650</th>\n",
        "      <th>word_freq_lab</th>\n",
        "      <th>word_freq_labs</th>\n",
        "      <th>word_freq_telnet</th>\n",
        "      <th>word_freq_857</th>\n",
        "      <th>word_freq_data</th>\n",
        "      <th>word_freq_415</th>\n",
        "      <th>word_freq_85</th>\n",
        "      <th>word_freq_technology</th>\n",
        "      <th>word_freq_1999</th>\n",
        "      <th>word_freq_parts</th>\n",
        "      <th>word_freq_pm</th>\n",
        "      <th>word_freq_direct</th>\n",
        "      <th>word_freq_cs</th>\n",
        "      <th>word_freq_meeting</th>\n",
        "      <th>word_freq_original</th>\n",
        "      <th>word_freq_project</th>\n",
        "      <th>word_freq_re</th>\n",
        "      <th>word_freq_edu</th>\n",
        "      <th>word_freq_table</th>\n",
        "      <th>word_freq_conference</th>\n",
        "      <th>char_freq_;</th>\n",
        "      <th>char_freq_(</th>\n",
        "      <th>char_freq_[</th>\n",
        "      <th>char_freq_!</th>\n",
        "      <th>char_freq_$</th>\n",
        "      <th>char_freq_#</th>\n",
        "      <th>capital_run_length_average</th>\n",
        "      <th>capital_run_length_longest</th>\n",
        "      <th>capital_run_length_total</th>\n",
        "      <th>is_spam</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "      <td>  4601.000000</td>\n",
        "      <td> 4601.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>    0.104553</td>\n",
        "      <td>    0.213015</td>\n",
        "      <td>    0.280656</td>\n",
        "      <td>    0.065425</td>\n",
        "      <td>    0.312223</td>\n",
        "      <td>    0.095901</td>\n",
        "      <td>    0.114208</td>\n",
        "      <td>    0.105295</td>\n",
        "      <td>    0.090067</td>\n",
        "      <td>    0.239413</td>\n",
        "      <td>    0.059824</td>\n",
        "      <td>    0.541702</td>\n",
        "      <td>    0.093930</td>\n",
        "      <td>    0.058626</td>\n",
        "      <td>    0.049205</td>\n",
        "      <td>    0.248848</td>\n",
        "      <td>    0.142586</td>\n",
        "      <td>    0.184745</td>\n",
        "      <td>    1.662100</td>\n",
        "      <td>    0.085577</td>\n",
        "      <td>    0.809761</td>\n",
        "      <td>    0.121202</td>\n",
        "      <td>    0.101645</td>\n",
        "      <td>    0.094269</td>\n",
        "      <td>    0.549504</td>\n",
        "      <td>    0.265384</td>\n",
        "      <td>    0.767305</td>\n",
        "      <td>    0.124845</td>\n",
        "      <td>    0.098915</td>\n",
        "      <td>    0.102852</td>\n",
        "      <td>    0.064753</td>\n",
        "      <td>    0.047048</td>\n",
        "      <td>    0.097229</td>\n",
        "      <td>    0.047835</td>\n",
        "      <td>    0.105412</td>\n",
        "      <td>    0.097477</td>\n",
        "      <td>    0.136953</td>\n",
        "      <td>    0.013201</td>\n",
        "      <td>    0.078629</td>\n",
        "      <td>    0.064834</td>\n",
        "      <td>    0.043667</td>\n",
        "      <td>    0.132339</td>\n",
        "      <td>    0.046099</td>\n",
        "      <td>    0.079196</td>\n",
        "      <td>    0.301224</td>\n",
        "      <td>    0.179824</td>\n",
        "      <td>    0.005444</td>\n",
        "      <td>    0.031869</td>\n",
        "      <td>    0.038575</td>\n",
        "      <td>    0.139030</td>\n",
        "      <td>    0.016976</td>\n",
        "      <td>    0.269071</td>\n",
        "      <td>    0.075811</td>\n",
        "      <td>    0.044238</td>\n",
        "      <td>    5.191515</td>\n",
        "      <td>   52.172789</td>\n",
        "      <td>   283.289285</td>\n",
        "      <td>    0.394045</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>    0.305358</td>\n",
        "      <td>    1.290575</td>\n",
        "      <td>    0.504143</td>\n",
        "      <td>    1.395151</td>\n",
        "      <td>    0.672513</td>\n",
        "      <td>    0.273824</td>\n",
        "      <td>    0.391441</td>\n",
        "      <td>    0.401071</td>\n",
        "      <td>    0.278616</td>\n",
        "      <td>    0.644755</td>\n",
        "      <td>    0.201545</td>\n",
        "      <td>    0.861698</td>\n",
        "      <td>    0.301036</td>\n",
        "      <td>    0.335184</td>\n",
        "      <td>    0.258843</td>\n",
        "      <td>    0.825792</td>\n",
        "      <td>    0.444055</td>\n",
        "      <td>    0.531122</td>\n",
        "      <td>    1.775481</td>\n",
        "      <td>    0.509767</td>\n",
        "      <td>    1.200810</td>\n",
        "      <td>    1.025756</td>\n",
        "      <td>    0.350286</td>\n",
        "      <td>    0.442636</td>\n",
        "      <td>    1.671349</td>\n",
        "      <td>    0.886955</td>\n",
        "      <td>    3.367292</td>\n",
        "      <td>    0.538576</td>\n",
        "      <td>    0.593327</td>\n",
        "      <td>    0.456682</td>\n",
        "      <td>    0.403393</td>\n",
        "      <td>    0.328559</td>\n",
        "      <td>    0.555907</td>\n",
        "      <td>    0.329445</td>\n",
        "      <td>    0.532260</td>\n",
        "      <td>    0.402623</td>\n",
        "      <td>    0.423451</td>\n",
        "      <td>    0.220651</td>\n",
        "      <td>    0.434672</td>\n",
        "      <td>    0.349916</td>\n",
        "      <td>    0.361205</td>\n",
        "      <td>    0.766819</td>\n",
        "      <td>    0.223812</td>\n",
        "      <td>    0.621976</td>\n",
        "      <td>    1.011687</td>\n",
        "      <td>    0.911119</td>\n",
        "      <td>    0.076274</td>\n",
        "      <td>    0.285735</td>\n",
        "      <td>    0.243471</td>\n",
        "      <td>    0.270355</td>\n",
        "      <td>    0.109394</td>\n",
        "      <td>    0.815672</td>\n",
        "      <td>    0.245882</td>\n",
        "      <td>    0.429342</td>\n",
        "      <td>   31.729449</td>\n",
        "      <td>  194.891310</td>\n",
        "      <td>   606.347851</td>\n",
        "      <td>    0.488698</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    1.000000</td>\n",
        "      <td>    1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    1.588000</td>\n",
        "      <td>    6.000000</td>\n",
        "      <td>    35.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.100000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    1.310000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.220000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.065000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    2.276000</td>\n",
        "      <td>   15.000000</td>\n",
        "      <td>    95.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.420000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.380000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.160000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.800000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.100000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    2.640000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    1.270000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.110000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.188000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    0.315000</td>\n",
        "      <td>    0.052000</td>\n",
        "      <td>    0.000000</td>\n",
        "      <td>    3.706000</td>\n",
        "      <td>   43.000000</td>\n",
        "      <td>   266.000000</td>\n",
        "      <td>    1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>    4.540000</td>\n",
        "      <td>   14.280000</td>\n",
        "      <td>    5.100000</td>\n",
        "      <td>   42.810000</td>\n",
        "      <td>   10.000000</td>\n",
        "      <td>    5.880000</td>\n",
        "      <td>    7.270000</td>\n",
        "      <td>   11.110000</td>\n",
        "      <td>    5.260000</td>\n",
        "      <td>   18.180000</td>\n",
        "      <td>    2.610000</td>\n",
        "      <td>    9.670000</td>\n",
        "      <td>    5.550000</td>\n",
        "      <td>   10.000000</td>\n",
        "      <td>    4.410000</td>\n",
        "      <td>   20.000000</td>\n",
        "      <td>    7.140000</td>\n",
        "      <td>    9.090000</td>\n",
        "      <td>   18.750000</td>\n",
        "      <td>   18.180000</td>\n",
        "      <td>   11.110000</td>\n",
        "      <td>   17.100000</td>\n",
        "      <td>    5.450000</td>\n",
        "      <td>   12.500000</td>\n",
        "      <td>   20.830000</td>\n",
        "      <td>   16.660000</td>\n",
        "      <td>   33.330000</td>\n",
        "      <td>    9.090000</td>\n",
        "      <td>   14.280000</td>\n",
        "      <td>    5.880000</td>\n",
        "      <td>   12.500000</td>\n",
        "      <td>    4.760000</td>\n",
        "      <td>   18.180000</td>\n",
        "      <td>    4.760000</td>\n",
        "      <td>   20.000000</td>\n",
        "      <td>    7.690000</td>\n",
        "      <td>    6.890000</td>\n",
        "      <td>    8.330000</td>\n",
        "      <td>   11.110000</td>\n",
        "      <td>    4.760000</td>\n",
        "      <td>    7.140000</td>\n",
        "      <td>   14.280000</td>\n",
        "      <td>    3.570000</td>\n",
        "      <td>   20.000000</td>\n",
        "      <td>   21.420000</td>\n",
        "      <td>   22.050000</td>\n",
        "      <td>    2.170000</td>\n",
        "      <td>   10.000000</td>\n",
        "      <td>    4.385000</td>\n",
        "      <td>    9.752000</td>\n",
        "      <td>    4.081000</td>\n",
        "      <td>   32.478000</td>\n",
        "      <td>    6.003000</td>\n",
        "      <td>   19.829000</td>\n",
        "      <td> 1102.500000</td>\n",
        "      <td> 9989.000000</td>\n",
        "      <td> 15841.000000</td>\n",
        "      <td>    1.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 131,
       "text": [
        "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
        "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
        "mean         0.104553           0.213015       0.280656      0.065425   \n",
        "std          0.305358           1.290575       0.504143      1.395151   \n",
        "min          0.000000           0.000000       0.000000      0.000000   \n",
        "25%          0.000000           0.000000       0.000000      0.000000   \n",
        "50%          0.000000           0.000000       0.000000      0.000000   \n",
        "75%          0.000000           0.000000       0.420000      0.000000   \n",
        "max          4.540000          14.280000       5.100000     42.810000   \n",
        "\n",
        "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
        "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
        "mean        0.312223        0.095901          0.114208            0.105295   \n",
        "std         0.672513        0.273824          0.391441            0.401071   \n",
        "min         0.000000        0.000000          0.000000            0.000000   \n",
        "25%         0.000000        0.000000          0.000000            0.000000   \n",
        "50%         0.000000        0.000000          0.000000            0.000000   \n",
        "75%         0.380000        0.000000          0.000000            0.000000   \n",
        "max        10.000000        5.880000          7.270000           11.110000   \n",
        "\n",
        "       word_freq_order  word_freq_mail  word_freq_receive  word_freq_will  \\\n",
        "count      4601.000000     4601.000000        4601.000000     4601.000000   \n",
        "mean          0.090067        0.239413           0.059824        0.541702   \n",
        "std           0.278616        0.644755           0.201545        0.861698   \n",
        "min           0.000000        0.000000           0.000000        0.000000   \n",
        "25%           0.000000        0.000000           0.000000        0.000000   \n",
        "50%           0.000000        0.000000           0.000000        0.100000   \n",
        "75%           0.000000        0.160000           0.000000        0.800000   \n",
        "max           5.260000       18.180000           2.610000        9.670000   \n",
        "\n",
        "       word_freq_people  word_freq_report  word_freq_addresses  \\\n",
        "count       4601.000000       4601.000000          4601.000000   \n",
        "mean           0.093930          0.058626             0.049205   \n",
        "std            0.301036          0.335184             0.258843   \n",
        "min            0.000000          0.000000             0.000000   \n",
        "25%            0.000000          0.000000             0.000000   \n",
        "50%            0.000000          0.000000             0.000000   \n",
        "75%            0.000000          0.000000             0.000000   \n",
        "max            5.550000         10.000000             4.410000   \n",
        "\n",
        "       word_freq_free  word_freq_business  word_freq_email  word_freq_you  \\\n",
        "count     4601.000000         4601.000000      4601.000000    4601.000000   \n",
        "mean         0.248848            0.142586         0.184745       1.662100   \n",
        "std          0.825792            0.444055         0.531122       1.775481   \n",
        "min          0.000000            0.000000         0.000000       0.000000   \n",
        "25%          0.000000            0.000000         0.000000       0.000000   \n",
        "50%          0.000000            0.000000         0.000000       1.310000   \n",
        "75%          0.100000            0.000000         0.000000       2.640000   \n",
        "max         20.000000            7.140000         9.090000      18.750000   \n",
        "\n",
        "       word_freq_credit  word_freq_your  word_freq_font  word_freq_000  \\\n",
        "count       4601.000000     4601.000000     4601.000000    4601.000000   \n",
        "mean           0.085577        0.809761        0.121202       0.101645   \n",
        "std            0.509767        1.200810        1.025756       0.350286   \n",
        "min            0.000000        0.000000        0.000000       0.000000   \n",
        "25%            0.000000        0.000000        0.000000       0.000000   \n",
        "50%            0.000000        0.220000        0.000000       0.000000   \n",
        "75%            0.000000        1.270000        0.000000       0.000000   \n",
        "max           18.180000       11.110000       17.100000       5.450000   \n",
        "\n",
        "       word_freq_money  word_freq_hp  word_freq_hpl  word_freq_george  \\\n",
        "count      4601.000000   4601.000000    4601.000000       4601.000000   \n",
        "mean          0.094269      0.549504       0.265384          0.767305   \n",
        "std           0.442636      1.671349       0.886955          3.367292   \n",
        "min           0.000000      0.000000       0.000000          0.000000   \n",
        "25%           0.000000      0.000000       0.000000          0.000000   \n",
        "50%           0.000000      0.000000       0.000000          0.000000   \n",
        "75%           0.000000      0.000000       0.000000          0.000000   \n",
        "max          12.500000     20.830000      16.660000         33.330000   \n",
        "\n",
        "       word_freq_650  word_freq_lab  word_freq_labs  word_freq_telnet  \\\n",
        "count    4601.000000    4601.000000     4601.000000       4601.000000   \n",
        "mean        0.124845       0.098915        0.102852          0.064753   \n",
        "std         0.538576       0.593327        0.456682          0.403393   \n",
        "min         0.000000       0.000000        0.000000          0.000000   \n",
        "25%         0.000000       0.000000        0.000000          0.000000   \n",
        "50%         0.000000       0.000000        0.000000          0.000000   \n",
        "75%         0.000000       0.000000        0.000000          0.000000   \n",
        "max         9.090000      14.280000        5.880000         12.500000   \n",
        "\n",
        "       word_freq_857  word_freq_data  word_freq_415  word_freq_85  \\\n",
        "count    4601.000000     4601.000000    4601.000000   4601.000000   \n",
        "mean        0.047048        0.097229       0.047835      0.105412   \n",
        "std         0.328559        0.555907       0.329445      0.532260   \n",
        "min         0.000000        0.000000       0.000000      0.000000   \n",
        "25%         0.000000        0.000000       0.000000      0.000000   \n",
        "50%         0.000000        0.000000       0.000000      0.000000   \n",
        "75%         0.000000        0.000000       0.000000      0.000000   \n",
        "max         4.760000       18.180000       4.760000     20.000000   \n",
        "\n",
        "       word_freq_technology  word_freq_1999  word_freq_parts  word_freq_pm  \\\n",
        "count           4601.000000     4601.000000      4601.000000   4601.000000   \n",
        "mean               0.097477        0.136953         0.013201      0.078629   \n",
        "std                0.402623        0.423451         0.220651      0.434672   \n",
        "min                0.000000        0.000000         0.000000      0.000000   \n",
        "25%                0.000000        0.000000         0.000000      0.000000   \n",
        "50%                0.000000        0.000000         0.000000      0.000000   \n",
        "75%                0.000000        0.000000         0.000000      0.000000   \n",
        "max                7.690000        6.890000         8.330000     11.110000   \n",
        "\n",
        "       word_freq_direct  word_freq_cs  word_freq_meeting  word_freq_original  \\\n",
        "count       4601.000000   4601.000000        4601.000000         4601.000000   \n",
        "mean           0.064834      0.043667           0.132339            0.046099   \n",
        "std            0.349916      0.361205           0.766819            0.223812   \n",
        "min            0.000000      0.000000           0.000000            0.000000   \n",
        "25%            0.000000      0.000000           0.000000            0.000000   \n",
        "50%            0.000000      0.000000           0.000000            0.000000   \n",
        "75%            0.000000      0.000000           0.000000            0.000000   \n",
        "max            4.760000      7.140000          14.280000            3.570000   \n",
        "\n",
        "       word_freq_project  word_freq_re  word_freq_edu  word_freq_table  \\\n",
        "count        4601.000000   4601.000000    4601.000000      4601.000000   \n",
        "mean            0.079196      0.301224       0.179824         0.005444   \n",
        "std             0.621976      1.011687       0.911119         0.076274   \n",
        "min             0.000000      0.000000       0.000000         0.000000   \n",
        "25%             0.000000      0.000000       0.000000         0.000000   \n",
        "50%             0.000000      0.000000       0.000000         0.000000   \n",
        "75%             0.000000      0.110000       0.000000         0.000000   \n",
        "max            20.000000     21.420000      22.050000         2.170000   \n",
        "\n",
        "       word_freq_conference  char_freq_;  char_freq_(  char_freq_[  \\\n",
        "count           4601.000000  4601.000000  4601.000000  4601.000000   \n",
        "mean               0.031869     0.038575     0.139030     0.016976   \n",
        "std                0.285735     0.243471     0.270355     0.109394   \n",
        "min                0.000000     0.000000     0.000000     0.000000   \n",
        "25%                0.000000     0.000000     0.000000     0.000000   \n",
        "50%                0.000000     0.000000     0.065000     0.000000   \n",
        "75%                0.000000     0.000000     0.188000     0.000000   \n",
        "max               10.000000     4.385000     9.752000     4.081000   \n",
        "\n",
        "       char_freq_!  char_freq_$  char_freq_#  capital_run_length_average  \\\n",
        "count  4601.000000  4601.000000  4601.000000                 4601.000000   \n",
        "mean      0.269071     0.075811     0.044238                    5.191515   \n",
        "std       0.815672     0.245882     0.429342                   31.729449   \n",
        "min       0.000000     0.000000     0.000000                    1.000000   \n",
        "25%       0.000000     0.000000     0.000000                    1.588000   \n",
        "50%       0.000000     0.000000     0.000000                    2.276000   \n",
        "75%       0.315000     0.052000     0.000000                    3.706000   \n",
        "max      32.478000     6.003000    19.829000                 1102.500000   \n",
        "\n",
        "       capital_run_length_longest  capital_run_length_total      is_spam  \n",
        "count                 4601.000000               4601.000000  4601.000000  \n",
        "mean                    52.172789                283.289285     0.394045  \n",
        "std                    194.891310                606.347851     0.488698  \n",
        "min                      1.000000                  1.000000     0.000000  \n",
        "25%                      6.000000                 35.000000     0.000000  \n",
        "50%                     15.000000                 95.000000     0.000000  \n",
        "75%                     43.000000                266.000000     1.000000  \n",
        "max                   9989.000000              15841.000000     1.000000  "
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 1: Explore the dataset and display some visualizations showing how the variables relate to each other"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spam_data.head()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>word_freq_make</th>\n",
        "      <th>word_freq_address</th>\n",
        "      <th>word_freq_all</th>\n",
        "      <th>word_freq_3d</th>\n",
        "      <th>word_freq_our</th>\n",
        "      <th>word_freq_over</th>\n",
        "      <th>word_freq_remove</th>\n",
        "      <th>word_freq_internet</th>\n",
        "      <th>word_freq_order</th>\n",
        "      <th>word_freq_mail</th>\n",
        "      <th>word_freq_receive</th>\n",
        "      <th>word_freq_will</th>\n",
        "      <th>word_freq_people</th>\n",
        "      <th>word_freq_report</th>\n",
        "      <th>word_freq_addresses</th>\n",
        "      <th>word_freq_free</th>\n",
        "      <th>word_freq_business</th>\n",
        "      <th>word_freq_email</th>\n",
        "      <th>word_freq_you</th>\n",
        "      <th>word_freq_credit</th>\n",
        "      <th>word_freq_your</th>\n",
        "      <th>word_freq_font</th>\n",
        "      <th>word_freq_000</th>\n",
        "      <th>word_freq_money</th>\n",
        "      <th>word_freq_hp</th>\n",
        "      <th>word_freq_hpl</th>\n",
        "      <th>word_freq_george</th>\n",
        "      <th>word_freq_650</th>\n",
        "      <th>word_freq_lab</th>\n",
        "      <th>word_freq_labs</th>\n",
        "      <th>word_freq_telnet</th>\n",
        "      <th>word_freq_857</th>\n",
        "      <th>word_freq_data</th>\n",
        "      <th>word_freq_415</th>\n",
        "      <th>word_freq_85</th>\n",
        "      <th>word_freq_technology</th>\n",
        "      <th>word_freq_1999</th>\n",
        "      <th>word_freq_parts</th>\n",
        "      <th>word_freq_pm</th>\n",
        "      <th>word_freq_direct</th>\n",
        "      <th>word_freq_cs</th>\n",
        "      <th>word_freq_meeting</th>\n",
        "      <th>word_freq_original</th>\n",
        "      <th>word_freq_project</th>\n",
        "      <th>word_freq_re</th>\n",
        "      <th>word_freq_edu</th>\n",
        "      <th>word_freq_table</th>\n",
        "      <th>word_freq_conference</th>\n",
        "      <th>char_freq_;</th>\n",
        "      <th>char_freq_(</th>\n",
        "      <th>char_freq_[</th>\n",
        "      <th>char_freq_!</th>\n",
        "      <th>char_freq_$</th>\n",
        "      <th>char_freq_#</th>\n",
        "      <th>capital_run_length_average</th>\n",
        "      <th>capital_run_length_longest</th>\n",
        "      <th>capital_run_length_total</th>\n",
        "      <th>is_spam</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.64</td>\n",
        "      <td> 0.64</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.32</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.64</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.32</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 1.29</td>\n",
        "      <td> 1.93</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.96</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.778</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 3.756</td>\n",
        "      <td>  61</td>\n",
        "      <td>  278</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0.21</td>\n",
        "      <td> 0.28</td>\n",
        "      <td> 0.50</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.14</td>\n",
        "      <td> 0.28</td>\n",
        "      <td> 0.21</td>\n",
        "      <td> 0.07</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.94</td>\n",
        "      <td> 0.21</td>\n",
        "      <td> 0.79</td>\n",
        "      <td> 0.65</td>\n",
        "      <td> 0.21</td>\n",
        "      <td> 0.14</td>\n",
        "      <td> 0.14</td>\n",
        "      <td> 0.07</td>\n",
        "      <td> 0.28</td>\n",
        "      <td> 3.47</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 1.59</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.43</td>\n",
        "      <td> 0.43</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.07</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.132</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.372</td>\n",
        "      <td> 0.180</td>\n",
        "      <td> 0.048</td>\n",
        "      <td> 5.114</td>\n",
        "      <td> 101</td>\n",
        "      <td> 1028</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0.06</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.71</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1.23</td>\n",
        "      <td> 0.19</td>\n",
        "      <td> 0.19</td>\n",
        "      <td> 0.12</td>\n",
        "      <td> 0.64</td>\n",
        "      <td> 0.25</td>\n",
        "      <td> 0.38</td>\n",
        "      <td> 0.45</td>\n",
        "      <td> 0.12</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 1.75</td>\n",
        "      <td> 0.06</td>\n",
        "      <td> 0.06</td>\n",
        "      <td> 1.03</td>\n",
        "      <td> 1.36</td>\n",
        "      <td> 0.32</td>\n",
        "      <td> 0.51</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1.16</td>\n",
        "      <td> 0.06</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.06</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.12</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.06</td>\n",
        "      <td> 0.06</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.01</td>\n",
        "      <td> 0.143</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.276</td>\n",
        "      <td> 0.184</td>\n",
        "      <td> 0.010</td>\n",
        "      <td> 9.821</td>\n",
        "      <td> 485</td>\n",
        "      <td> 2259</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.63</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.63</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.63</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 3.18</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.137</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.137</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 3.537</td>\n",
        "      <td>  40</td>\n",
        "      <td>  191</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.63</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.63</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.63</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 3.18</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.135</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.135</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 3.537</td>\n",
        "      <td>  40</td>\n",
        "      <td>  191</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 132,
       "text": [
        "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
        "0            0.00               0.64           0.64             0   \n",
        "1            0.21               0.28           0.50             0   \n",
        "2            0.06               0.00           0.71             0   \n",
        "3            0.00               0.00           0.00             0   \n",
        "4            0.00               0.00           0.00             0   \n",
        "\n",
        "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
        "0           0.32            0.00              0.00                0.00   \n",
        "1           0.14            0.28              0.21                0.07   \n",
        "2           1.23            0.19              0.19                0.12   \n",
        "3           0.63            0.00              0.31                0.63   \n",
        "4           0.63            0.00              0.31                0.63   \n",
        "\n",
        "   word_freq_order  word_freq_mail  word_freq_receive  word_freq_will  \\\n",
        "0             0.00            0.00               0.00            0.64   \n",
        "1             0.00            0.94               0.21            0.79   \n",
        "2             0.64            0.25               0.38            0.45   \n",
        "3             0.31            0.63               0.31            0.31   \n",
        "4             0.31            0.63               0.31            0.31   \n",
        "\n",
        "   word_freq_people  word_freq_report  word_freq_addresses  word_freq_free  \\\n",
        "0              0.00              0.00                 0.00            0.32   \n",
        "1              0.65              0.21                 0.14            0.14   \n",
        "2              0.12              0.00                 1.75            0.06   \n",
        "3              0.31              0.00                 0.00            0.31   \n",
        "4              0.31              0.00                 0.00            0.31   \n",
        "\n",
        "   word_freq_business  word_freq_email  word_freq_you  word_freq_credit  \\\n",
        "0                0.00             1.29           1.93              0.00   \n",
        "1                0.07             0.28           3.47              0.00   \n",
        "2                0.06             1.03           1.36              0.32   \n",
        "3                0.00             0.00           3.18              0.00   \n",
        "4                0.00             0.00           3.18              0.00   \n",
        "\n",
        "   word_freq_your  word_freq_font  word_freq_000  word_freq_money  \\\n",
        "0            0.96               0           0.00             0.00   \n",
        "1            1.59               0           0.43             0.43   \n",
        "2            0.51               0           1.16             0.06   \n",
        "3            0.31               0           0.00             0.00   \n",
        "4            0.31               0           0.00             0.00   \n",
        "\n",
        "   word_freq_hp  word_freq_hpl  word_freq_george  word_freq_650  \\\n",
        "0             0              0                 0              0   \n",
        "1             0              0                 0              0   \n",
        "2             0              0                 0              0   \n",
        "3             0              0                 0              0   \n",
        "4             0              0                 0              0   \n",
        "\n",
        "   word_freq_lab  word_freq_labs  word_freq_telnet  word_freq_857  \\\n",
        "0              0               0                 0              0   \n",
        "1              0               0                 0              0   \n",
        "2              0               0                 0              0   \n",
        "3              0               0                 0              0   \n",
        "4              0               0                 0              0   \n",
        "\n",
        "   word_freq_data  word_freq_415  word_freq_85  word_freq_technology  \\\n",
        "0               0              0             0                     0   \n",
        "1               0              0             0                     0   \n",
        "2               0              0             0                     0   \n",
        "3               0              0             0                     0   \n",
        "4               0              0             0                     0   \n",
        "\n",
        "   word_freq_1999  word_freq_parts  word_freq_pm  word_freq_direct  \\\n",
        "0            0.00                0             0              0.00   \n",
        "1            0.07                0             0              0.00   \n",
        "2            0.00                0             0              0.06   \n",
        "3            0.00                0             0              0.00   \n",
        "4            0.00                0             0              0.00   \n",
        "\n",
        "   word_freq_cs  word_freq_meeting  word_freq_original  word_freq_project  \\\n",
        "0             0                  0                0.00                  0   \n",
        "1             0                  0                0.00                  0   \n",
        "2             0                  0                0.12                  0   \n",
        "3             0                  0                0.00                  0   \n",
        "4             0                  0                0.00                  0   \n",
        "\n",
        "   word_freq_re  word_freq_edu  word_freq_table  word_freq_conference  \\\n",
        "0          0.00           0.00                0                     0   \n",
        "1          0.00           0.00                0                     0   \n",
        "2          0.06           0.06                0                     0   \n",
        "3          0.00           0.00                0                     0   \n",
        "4          0.00           0.00                0                     0   \n",
        "\n",
        "   char_freq_;  char_freq_(  char_freq_[  char_freq_!  char_freq_$  \\\n",
        "0         0.00        0.000            0        0.778        0.000   \n",
        "1         0.00        0.132            0        0.372        0.180   \n",
        "2         0.01        0.143            0        0.276        0.184   \n",
        "3         0.00        0.137            0        0.137        0.000   \n",
        "4         0.00        0.135            0        0.135        0.000   \n",
        "\n",
        "   char_freq_#  capital_run_length_average  capital_run_length_longest  \\\n",
        "0        0.000                       3.756                          61   \n",
        "1        0.048                       5.114                         101   \n",
        "2        0.010                       9.821                         485   \n",
        "3        0.000                       3.537                          40   \n",
        "4        0.000                       3.537                          40   \n",
        "\n",
        "   capital_run_length_total  is_spam  \n",
        "0                       278        1  \n",
        "1                      1028        1  \n",
        "2                      2259        1  \n",
        "3                       191        1  \n",
        "4                       191        1  "
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spam_data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 133,
       "text": [
        "(4601, 58)"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spam_data.info()\n",
      "#no null data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 4601 entries, 0 to 4600\n",
        "Data columns (total 58 columns):\n",
        "word_freq_make                4601 non-null float64\n",
        "word_freq_address             4601 non-null float64\n",
        "word_freq_all                 4601 non-null float64\n",
        "word_freq_3d                  4601 non-null float64\n",
        "word_freq_our                 4601 non-null float64\n",
        "word_freq_over                4601 non-null float64\n",
        "word_freq_remove              4601 non-null float64\n",
        "word_freq_internet            4601 non-null float64\n",
        "word_freq_order               4601 non-null float64\n",
        "word_freq_mail                4601 non-null float64\n",
        "word_freq_receive             4601 non-null float64\n",
        "word_freq_will                4601 non-null float64\n",
        "word_freq_people              4601 non-null float64\n",
        "word_freq_report              4601 non-null float64\n",
        "word_freq_addresses           4601 non-null float64\n",
        "word_freq_free                4601 non-null float64\n",
        "word_freq_business            4601 non-null float64\n",
        "word_freq_email               4601 non-null float64\n",
        "word_freq_you                 4601 non-null float64\n",
        "word_freq_credit              4601 non-null float64\n",
        "word_freq_your                4601 non-null float64\n",
        "word_freq_font                4601 non-null float64\n",
        "word_freq_000                 4601 non-null float64\n",
        "word_freq_money               4601 non-null float64\n",
        "word_freq_hp                  4601 non-null float64\n",
        "word_freq_hpl                 4601 non-null float64\n",
        "word_freq_george              4601 non-null float64\n",
        "word_freq_650                 4601 non-null float64\n",
        "word_freq_lab                 4601 non-null float64\n",
        "word_freq_labs                4601 non-null float64\n",
        "word_freq_telnet              4601 non-null float64\n",
        "word_freq_857                 4601 non-null float64\n",
        "word_freq_data                4601 non-null float64\n",
        "word_freq_415                 4601 non-null float64\n",
        "word_freq_85                  4601 non-null float64\n",
        "word_freq_technology          4601 non-null float64\n",
        "word_freq_1999                4601 non-null float64\n",
        "word_freq_parts               4601 non-null float64\n",
        "word_freq_pm                  4601 non-null float64\n",
        "word_freq_direct              4601 non-null float64\n",
        "word_freq_cs                  4601 non-null float64\n",
        "word_freq_meeting             4601 non-null float64\n",
        "word_freq_original            4601 non-null float64\n",
        "word_freq_project             4601 non-null float64\n",
        "word_freq_re                  4601 non-null float64\n",
        "word_freq_edu                 4601 non-null float64\n",
        "word_freq_table               4601 non-null float64\n",
        "word_freq_conference          4601 non-null float64\n",
        "char_freq_;                   4601 non-null float64\n",
        "char_freq_(                   4601 non-null float64\n",
        "char_freq_[                   4601 non-null float64\n",
        "char_freq_!                   4601 non-null float64\n",
        "char_freq_$                   4601 non-null float64\n",
        "char_freq_#                   4601 non-null float64\n",
        "capital_run_length_average    4601 non-null float64\n",
        "capital_run_length_longest    4601 non-null int64\n",
        "capital_run_length_total      4601 non-null int64\n",
        "is_spam                       4601 non-null int64\n",
        "dtypes: float64(55), int64(3)"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 2: Build a simple logistic regression and visualize it\n",
      "use the variable \"capital_run_length_longest\" to predict \"is_spam\" How accurate is this single feature?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Import Packages \n",
      "from sklearn import metrics\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import classification_report\n",
      "\n",
      "#fill na, define features and target numpy arrays\n",
      "numerical_features = spam_data['capital_run_length_longest']\n",
      "features_array = numerical_features.fillna(numerical_features.dropna().median()).values\n",
      "target = spam_data.is_spam.values\n",
      "\n",
      "# train test split\n",
      "features_train, features_test, target_train, target_test = train_test_split(features_array, target, test_size=0.20, random_state=10)\n",
      "\n",
      "\n",
      "print features_train.shape\n",
      "print target_train.shape\n",
      "print features_test.shape\n",
      "print target_test.shape\n",
      "print features_train\n",
      "print target_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3680,)\n",
        "(3680,)\n",
        "(921,)\n",
        "(921,)\n",
        "[ 6 10 11 ..., 11 69 30]\n",
        "[0 0 1 ..., 0 1 1]\n"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#reshape single feature arrays\n",
      "features_train = features_train.reshape(3680,1)\n",
      "features_test = features_test.reshape(921,1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fit and predict the model\n",
      "lr = LogisticRegression()\n",
      "lr.fit(features_train, target_train)\n",
      "target_predicted = lr.predict(features_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Evaluate Score\n",
      "print 'Accuracy is ' + str(metrics.accuracy_score(target_test, target_predicted))\n",
      "#print metrics.roc_auc_score(target_test, probs[:, 1])\n",
      "print classification_report(target_test, target_predicted,\n",
      "                      target_names=['not spam', 'spam'])\n",
      "\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy is 0.745928338762\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "   not spam       0.72      0.95      0.82       559\n",
        "       spam       0.84      0.44      0.57       362\n",
        "\n",
        "avg / total       0.77      0.75      0.72       921\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 138
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 3: Use train-test spit to split your data at a 30% mark and run another logistic regression using all variables\n",
      "use random state = 12 so that we can compare results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data munging\n",
      "spam_features = spam_data[spam_data.columns[0:57]]\n",
      "spam_array = spam_features.fillna(spam_features.dropna().median()).values\n",
      "spam_features = spam_features.fillna(spam_features.dropna().median())\n",
      "spam_target = spam_data.is_spam.values\n",
      "\n",
      "# train test split\n",
      "X_train, X_test, Y_train, Y_test = train_test_split(spam_array, spam_target, test_size=0.30, random_state=10)\n",
      "print X_train.shape\n",
      "print X_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3220, 57)\n",
        "(1381, 57)\n"
       ]
      }
     ],
     "prompt_number": 168
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Fit and predict model\n",
      "lr.fit(X_train, Y_train)\n",
      "Y_predicted = lr.predict(X_test)\n",
      "\n",
      "#Evaluate Score\n",
      "print 'Accuracy is ' + str(metrics.accuracy_score(Y_test, Y_predicted))\n",
      "#print metrics.roc_auc_score(target_test, probs[:, 1])\n",
      "print classification_report(Y_test, Y_predicted,\n",
      "                      target_names=['not spam', 'spam'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy is 0.926140477915\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "   not spam       0.93      0.95      0.94       821\n",
        "       spam       0.92      0.89      0.91       560\n",
        "\n",
        "avg / total       0.93      0.93      0.93      1381\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#The model is much more accurate with over 92% accuracy."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 170
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 4: Apply cross validation to see how the model fares across different splits of your data\n",
      "Use cross validation to score your model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "score = cross_val_score(lr, spam_features, spam_target, cv=5, scoring ='accuracy')\n",
      "print score.mean()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.912391909726\n"
       ]
      }
     ],
     "prompt_number": 171
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 5: Compare Performance of Logistic Regression to KNN with 3 neighbors\n",
      "Which model is more accurate?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#KNN with 3 Neighbors\n",
      "from sklearn import neighbors, datasets, feature_selection\n",
      "\n",
      "knn = neighbors.KNeighborsClassifier(3, weights='uniform')\n",
      "knn.fit(X_train, Y_train)\n",
      "scores = cross_val_score(knn, X_test, Y_test, cv=5)\n",
      "print scores.mean()\n",
      "#Knn score is 75% which is much poorer."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.753777533616\n"
       ]
      }
     ],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spam_features.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 173,
       "text": [
        "array([[  0.00000000e+00,   6.40000000e-01,   6.40000000e-01, ...,\n",
        "          3.75600000e+00,   6.10000000e+01,   2.78000000e+02],\n",
        "       [  2.10000000e-01,   2.80000000e-01,   5.00000000e-01, ...,\n",
        "          5.11400000e+00,   1.01000000e+02,   1.02800000e+03],\n",
        "       [  6.00000000e-02,   0.00000000e+00,   7.10000000e-01, ...,\n",
        "          9.82100000e+00,   4.85000000e+02,   2.25900000e+03],\n",
        "       ..., \n",
        "       [  3.00000000e-01,   0.00000000e+00,   3.00000000e-01, ...,\n",
        "          1.40400000e+00,   6.00000000e+00,   1.18000000e+02],\n",
        "       [  9.60000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n",
        "          1.14700000e+00,   5.00000000e+00,   7.80000000e+01],\n",
        "       [  0.00000000e+00,   0.00000000e+00,   6.50000000e-01, ...,\n",
        "          1.25000000e+00,   5.00000000e+00,   4.00000000e+01]])"
       ]
      }
     ],
     "prompt_number": 173
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 6: Evaluate Feature Importance\n",
      "Which features are the most influential in this model?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Can probably use regression tree\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "treeclf = DecisionTreeClassifier(max_depth = 10, random_state=10)\n",
      "treeclf.fit(X_train, Y_train)\n",
      "spam_feature_importance = pd.DataFrame({'feature':spam_features.columns, 'importance':treeclf.feature_importances_})\n",
      "spam_feature_importance.sort(columns = 'importance',ascending =False)\n",
      "#How to use Transform?\n",
      "#spam_trans = lr.transform(spam_array)\n",
      "#spam_array\n",
      "        \n",
      "# exclaimation point frequency is the most imporant, longest consequtive capital letter and frequency of the word \"remove\"\n",
      "#are also very important\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>feature</th>\n",
        "      <th>importance</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>51</th>\n",
        "      <td>                char_freq_!</td>\n",
        "      <td> 0.405779</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>55</th>\n",
        "      <td> capital_run_length_longest</td>\n",
        "      <td> 0.119364</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>           word_freq_remove</td>\n",
        "      <td> 0.106517</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>             word_freq_free</td>\n",
        "      <td> 0.064541</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>52</th>\n",
        "      <td>                char_freq_$</td>\n",
        "      <td> 0.045635</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td>               word_freq_hp</td>\n",
        "      <td> 0.035186</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td>           word_freq_george</td>\n",
        "      <td> 0.023760</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>45</th>\n",
        "      <td>              word_freq_edu</td>\n",
        "      <td> 0.021518</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>54</th>\n",
        "      <td> capital_run_length_average</td>\n",
        "      <td> 0.018010</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td>            word_freq_money</td>\n",
        "      <td> 0.015528</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td>         word_freq_internet</td>\n",
        "      <td> 0.014995</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>56</th>\n",
        "      <td>   capital_run_length_total</td>\n",
        "      <td> 0.014953</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>49</th>\n",
        "      <td>                char_freq_(</td>\n",
        "      <td> 0.011275</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td>             word_freq_your</td>\n",
        "      <td> 0.011101</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td>              word_freq_our</td>\n",
        "      <td> 0.010274</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>44</th>\n",
        "      <td>               word_freq_re</td>\n",
        "      <td> 0.007052</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>           word_freq_report</td>\n",
        "      <td> 0.005474</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>41</th>\n",
        "      <td>          word_freq_meeting</td>\n",
        "      <td> 0.005343</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>           word_freq_people</td>\n",
        "      <td> 0.004756</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>39</th>\n",
        "      <td>           word_freq_direct</td>\n",
        "      <td> 0.004549</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td>             word_freq_over</td>\n",
        "      <td> 0.004135</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td>              word_freq_hpl</td>\n",
        "      <td> 0.004033</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>47</th>\n",
        "      <td>       word_freq_conference</td>\n",
        "      <td> 0.003808</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48</th>\n",
        "      <td>                char_freq_;</td>\n",
        "      <td> 0.003746</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td>            word_freq_order</td>\n",
        "      <td> 0.003589</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>          word_freq_receive</td>\n",
        "      <td> 0.003134</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>              word_freq_all</td>\n",
        "      <td> 0.002825</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td>              word_freq_650</td>\n",
        "      <td> 0.002705</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>33</th>\n",
        "      <td>              word_freq_415</td>\n",
        "      <td> 0.002587</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td>             word_freq_labs</td>\n",
        "      <td> 0.002563</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>             word_freq_will</td>\n",
        "      <td> 0.002336</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td>              word_freq_000</td>\n",
        "      <td> 0.002328</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td>         word_freq_business</td>\n",
        "      <td> 0.002199</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td>       word_freq_technology</td>\n",
        "      <td> 0.002198</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>42</th>\n",
        "      <td>         word_freq_original</td>\n",
        "      <td> 0.002119</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>              word_freq_you</td>\n",
        "      <td> 0.001840</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td>             word_freq_font</td>\n",
        "      <td> 0.001812</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>32</th>\n",
        "      <td>             word_freq_data</td>\n",
        "      <td> 0.001416</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>             word_freq_make</td>\n",
        "      <td> 0.001387</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>          word_freq_address</td>\n",
        "      <td> 0.001327</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td>            word_freq_email</td>\n",
        "      <td> 0.001306</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td>             word_freq_mail</td>\n",
        "      <td> 0.000995</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>40</th>\n",
        "      <td>               word_freq_cs</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>               word_freq_3d</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>53</th>\n",
        "      <td>                char_freq_#</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>        word_freq_addresses</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50</th>\n",
        "      <td>                char_freq_[</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>           word_freq_credit</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>38</th>\n",
        "      <td>               word_freq_pm</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>30</th>\n",
        "      <td>           word_freq_telnet</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>46</th>\n",
        "      <td>            word_freq_table</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>31</th>\n",
        "      <td>              word_freq_857</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td>               word_freq_85</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>43</th>\n",
        "      <td>          word_freq_project</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36</th>\n",
        "      <td>             word_freq_1999</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>37</th>\n",
        "      <td>            word_freq_parts</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td>              word_freq_lab</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 174,
       "text": [
        "                       feature  importance\n",
        "51                 char_freq_!    0.405779\n",
        "55  capital_run_length_longest    0.119364\n",
        "6             word_freq_remove    0.106517\n",
        "15              word_freq_free    0.064541\n",
        "52                 char_freq_$    0.045635\n",
        "24                word_freq_hp    0.035186\n",
        "26            word_freq_george    0.023760\n",
        "45               word_freq_edu    0.021518\n",
        "54  capital_run_length_average    0.018010\n",
        "23             word_freq_money    0.015528\n",
        "7           word_freq_internet    0.014995\n",
        "56    capital_run_length_total    0.014953\n",
        "49                 char_freq_(    0.011275\n",
        "20              word_freq_your    0.011101\n",
        "4                word_freq_our    0.010274\n",
        "44                word_freq_re    0.007052\n",
        "13            word_freq_report    0.005474\n",
        "41           word_freq_meeting    0.005343\n",
        "12            word_freq_people    0.004756\n",
        "39            word_freq_direct    0.004549\n",
        "5               word_freq_over    0.004135\n",
        "25               word_freq_hpl    0.004033\n",
        "47        word_freq_conference    0.003808\n",
        "48                 char_freq_;    0.003746\n",
        "8              word_freq_order    0.003589\n",
        "10           word_freq_receive    0.003134\n",
        "2                word_freq_all    0.002825\n",
        "27               word_freq_650    0.002705\n",
        "33               word_freq_415    0.002587\n",
        "29              word_freq_labs    0.002563\n",
        "11              word_freq_will    0.002336\n",
        "22               word_freq_000    0.002328\n",
        "16          word_freq_business    0.002199\n",
        "35        word_freq_technology    0.002198\n",
        "42          word_freq_original    0.002119\n",
        "18               word_freq_you    0.001840\n",
        "21              word_freq_font    0.001812\n",
        "32              word_freq_data    0.001416\n",
        "0               word_freq_make    0.001387\n",
        "1            word_freq_address    0.001327\n",
        "17             word_freq_email    0.001306\n",
        "9               word_freq_mail    0.000995\n",
        "40                word_freq_cs    0.000000\n",
        "3                 word_freq_3d    0.000000\n",
        "53                 char_freq_#    0.000000\n",
        "14         word_freq_addresses    0.000000\n",
        "50                 char_freq_[    0.000000\n",
        "19            word_freq_credit    0.000000\n",
        "38                word_freq_pm    0.000000\n",
        "30            word_freq_telnet    0.000000\n",
        "46             word_freq_table    0.000000\n",
        "31               word_freq_857    0.000000\n",
        "34                word_freq_85    0.000000\n",
        "43           word_freq_project    0.000000\n",
        "36              word_freq_1999    0.000000\n",
        "37             word_freq_parts    0.000000\n",
        "28               word_freq_lab    0.000000"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# examine the coefficients\n",
      "X_train, X_test, Y_train, Y_test = train_test_split(spam_features, spam_target, test_size=0.30, random_state=10)\n",
      "lr.fit(X_train, Y_train)\n",
      "Y_predicted = lr.predict(X_test)\n",
      "pd.DataFrame(zip(spam_features.columns, np.transpose(lr.coef_)\n",
      "            \n",
      "#From the coef, it looks like the most important features are char_freq_$, word_freq_remove, word_freq_000, and word_freq_george\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>             word_freq_make</td>\n",
        "      <td>   [-0.229595990466]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>          word_freq_address</td>\n",
        "      <td>   [-0.133148206058]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>              word_freq_all</td>\n",
        "      <td>    [0.201110998098]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>               word_freq_3d</td>\n",
        "      <td>    [0.788756248224]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td>              word_freq_our</td>\n",
        "      <td>    [0.647100787542]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td>             word_freq_over</td>\n",
        "      <td>     [1.09376208727]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>           word_freq_remove</td>\n",
        "      <td>     [2.38083462651]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td>         word_freq_internet</td>\n",
        "      <td>    [0.563623202696]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td>            word_freq_order</td>\n",
        "      <td>    [0.286169283771]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td>             word_freq_mail</td>\n",
        "      <td>    [0.131563985228]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>          word_freq_receive</td>\n",
        "      <td>   [-0.158576461141]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>             word_freq_will</td>\n",
        "      <td>   [-0.158505549927]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>           word_freq_people</td>\n",
        "      <td>   [-0.253598782437]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>           word_freq_report</td>\n",
        "      <td>    [0.255004945279]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>        word_freq_addresses</td>\n",
        "      <td>    [0.942718105796]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>             word_freq_free</td>\n",
        "      <td>    [0.880959774319]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td>         word_freq_business</td>\n",
        "      <td>    [0.782025449288]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td>            word_freq_email</td>\n",
        "      <td>    [0.125702436219]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>              word_freq_you</td>\n",
        "      <td>   [0.0469589351301]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>           word_freq_credit</td>\n",
        "      <td>    [0.990844009977]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td>             word_freq_your</td>\n",
        "      <td>     [0.26185191552]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td>             word_freq_font</td>\n",
        "      <td>     [0.21867929135]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td>              word_freq_000</td>\n",
        "      <td>     [1.96439916296]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td>            word_freq_money</td>\n",
        "      <td>    [0.685765070971]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td>               word_freq_hp</td>\n",
        "      <td>    [-1.44734338321]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td>              word_freq_hpl</td>\n",
        "      <td>     [-1.3263916504]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td>           word_freq_george</td>\n",
        "      <td>    [-3.68358292202]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td>              word_freq_650</td>\n",
        "      <td>    [0.379333661387]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td>              word_freq_lab</td>\n",
        "      <td>    [-1.22608934872]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td>             word_freq_labs</td>\n",
        "      <td>   [-0.682254107854]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>30</th>\n",
        "      <td>           word_freq_telnet</td>\n",
        "      <td>   [-0.262143738363]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>31</th>\n",
        "      <td>              word_freq_857</td>\n",
        "      <td>   [-0.113925663801]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>32</th>\n",
        "      <td>             word_freq_data</td>\n",
        "      <td>   [-0.808928696555]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>33</th>\n",
        "      <td>              word_freq_415</td>\n",
        "      <td>   [0.0271073632412]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td>               word_freq_85</td>\n",
        "      <td>     [-1.1990528954]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td>       word_freq_technology</td>\n",
        "      <td>    [0.482371595044]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36</th>\n",
        "      <td>             word_freq_1999</td>\n",
        "      <td>   [0.0638589512807]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>37</th>\n",
        "      <td>            word_freq_parts</td>\n",
        "      <td>   [-0.450766578234]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>38</th>\n",
        "      <td>               word_freq_pm</td>\n",
        "      <td>   [-0.825249793736]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>39</th>\n",
        "      <td>           word_freq_direct</td>\n",
        "      <td>   [-0.320388207674]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>40</th>\n",
        "      <td>               word_freq_cs</td>\n",
        "      <td>    [-1.17195940237]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>41</th>\n",
        "      <td>          word_freq_meeting</td>\n",
        "      <td>    [-1.73669723832]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>42</th>\n",
        "      <td>         word_freq_original</td>\n",
        "      <td>   [-0.722164563012]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>43</th>\n",
        "      <td>          word_freq_project</td>\n",
        "      <td>     [-1.3308022561]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>44</th>\n",
        "      <td>               word_freq_re</td>\n",
        "      <td>   [-0.684654103487]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>45</th>\n",
        "      <td>              word_freq_edu</td>\n",
        "      <td>    [-1.19980113769]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>46</th>\n",
        "      <td>            word_freq_table</td>\n",
        "      <td>   [-0.376447926457]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>47</th>\n",
        "      <td>       word_freq_conference</td>\n",
        "      <td>    [-1.39256972932]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48</th>\n",
        "      <td>                char_freq_;</td>\n",
        "      <td>    [-1.00763681517]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>49</th>\n",
        "      <td>                char_freq_(</td>\n",
        "      <td>   [0.0736982659225]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50</th>\n",
        "      <td>                char_freq_[</td>\n",
        "      <td>   [-0.324542163947]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>51</th>\n",
        "      <td>                char_freq_!</td>\n",
        "      <td>    [0.266449930846]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>52</th>\n",
        "      <td>                char_freq_$</td>\n",
        "      <td>     [3.10700349885]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>53</th>\n",
        "      <td>                char_freq_#</td>\n",
        "      <td>     [1.09253648001]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>54</th>\n",
        "      <td> capital_run_length_average</td>\n",
        "      <td>  [-0.0120213073166]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>55</th>\n",
        "      <td> capital_run_length_longest</td>\n",
        "      <td>  [0.00733458516798]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>56</th>\n",
        "      <td>   capital_run_length_total</td>\n",
        "      <td> [0.000537823809034]</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 179,
       "text": [
        "                             0                    1\n",
        "0               word_freq_make    [-0.229595990466]\n",
        "1            word_freq_address    [-0.133148206058]\n",
        "2                word_freq_all     [0.201110998098]\n",
        "3                 word_freq_3d     [0.788756248224]\n",
        "4                word_freq_our     [0.647100787542]\n",
        "5               word_freq_over      [1.09376208727]\n",
        "6             word_freq_remove      [2.38083462651]\n",
        "7           word_freq_internet     [0.563623202696]\n",
        "8              word_freq_order     [0.286169283771]\n",
        "9               word_freq_mail     [0.131563985228]\n",
        "10           word_freq_receive    [-0.158576461141]\n",
        "11              word_freq_will    [-0.158505549927]\n",
        "12            word_freq_people    [-0.253598782437]\n",
        "13            word_freq_report     [0.255004945279]\n",
        "14         word_freq_addresses     [0.942718105796]\n",
        "15              word_freq_free     [0.880959774319]\n",
        "16          word_freq_business     [0.782025449288]\n",
        "17             word_freq_email     [0.125702436219]\n",
        "18               word_freq_you    [0.0469589351301]\n",
        "19            word_freq_credit     [0.990844009977]\n",
        "20              word_freq_your      [0.26185191552]\n",
        "21              word_freq_font      [0.21867929135]\n",
        "22               word_freq_000      [1.96439916296]\n",
        "23             word_freq_money     [0.685765070971]\n",
        "24                word_freq_hp     [-1.44734338321]\n",
        "25               word_freq_hpl      [-1.3263916504]\n",
        "26            word_freq_george     [-3.68358292202]\n",
        "27               word_freq_650     [0.379333661387]\n",
        "28               word_freq_lab     [-1.22608934872]\n",
        "29              word_freq_labs    [-0.682254107854]\n",
        "30            word_freq_telnet    [-0.262143738363]\n",
        "31               word_freq_857    [-0.113925663801]\n",
        "32              word_freq_data    [-0.808928696555]\n",
        "33               word_freq_415    [0.0271073632412]\n",
        "34                word_freq_85      [-1.1990528954]\n",
        "35        word_freq_technology     [0.482371595044]\n",
        "36              word_freq_1999    [0.0638589512807]\n",
        "37             word_freq_parts    [-0.450766578234]\n",
        "38                word_freq_pm    [-0.825249793736]\n",
        "39            word_freq_direct    [-0.320388207674]\n",
        "40                word_freq_cs     [-1.17195940237]\n",
        "41           word_freq_meeting     [-1.73669723832]\n",
        "42          word_freq_original    [-0.722164563012]\n",
        "43           word_freq_project      [-1.3308022561]\n",
        "44                word_freq_re    [-0.684654103487]\n",
        "45               word_freq_edu     [-1.19980113769]\n",
        "46             word_freq_table    [-0.376447926457]\n",
        "47        word_freq_conference     [-1.39256972932]\n",
        "48                 char_freq_;     [-1.00763681517]\n",
        "49                 char_freq_(    [0.0736982659225]\n",
        "50                 char_freq_[    [-0.324542163947]\n",
        "51                 char_freq_!     [0.266449930846]\n",
        "52                 char_freq_$      [3.10700349885]\n",
        "53                 char_freq_#      [1.09253648001]\n",
        "54  capital_run_length_average   [-0.0120213073166]\n",
        "55  capital_run_length_longest   [0.00733458516798]\n",
        "56    capital_run_length_total  [0.000537823809034]"
       ]
      }
     ],
     "prompt_number": 179
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 7: Plot the ROC Curve for the logistic regression you chose\u00b6"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "from sklearn.metrics import auc\n",
      "\n",
      "proba_lr = lr.predict_proba(X_test)\n",
      "\n",
      "def plot_roc_curve(Y_test, proba_lr, this_label):\n",
      "    fpr, tpr, thresholds = roc_curve(Y_test, proba_lr[:, 1])\n",
      "    \n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    # Plot ROC curve\n",
      "    plt.plot(fpr, tpr, label= this_label + ', ROC Area = %0.3f' % roc_auc)\n",
      "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.0])\n",
      "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
      "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
      "    plt.title('ROC')\n",
      "    plt.legend(loc=\"lower right\")\n",
      "    \n",
      "plot_roc_curve(Y_test, proba_lr, 'Curve')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEbCAYAAADeeCN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f4a91030210>"
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 8: Demonstrate how the accurary of your predictions changes when you set your threshold to levels other than 50%"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#manually change the threshold of the model\n",
      "prob_lr = lr.predict_proba(X_test)\n",
      "prob_lr_re = prob_lr.reshape(2762,1)\n",
      "for x in range(len(prob_lr_re)):\n",
      "    if prob_lr_re[x] > 0.1:\n",
      "        prob_lr_re[x] = 1\n",
      "    else:\n",
      "        prob_lr_re[x] = 0 \n",
      "prob_lr_re = prob_lr_re.reshape(1381,2)\n",
      "spam_predict = prob_lr_re[:,1]\n",
      "print classification_report(Y_test,spam_predict,\n",
      "                      target_names=['not spam', 'spam'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "   not spam       0.99      0.70      0.82       821\n",
        "       spam       0.69      0.99      0.81       560\n",
        "\n",
        "avg / total       0.87      0.82      0.82      1381\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 229
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "I applied different values to the code above by changing the percent decimal in the line \"prob_lr_re[x] > <percent decimal>:\"\n",
      "to choose the thres hold. I notice that as the threshold increases the precision of spam prediction increases but the recall\n",
      "decreases which is expected when you have high specificity and low sensitivity. \n",
      "The opposite occurs when I reduce the threshold, precision decreases but the recall increases. \n",
      "And the scores for not spam prediction moves in the opposite direction of the spam prediction.\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 230,
       "text": [
        "'\\nI applied different values to the code above by changing the if the line \"prob_lr_re[x] > <percent decimal>:\"\\nto choose the thres hold. I notice that as the threshold increases the precision of spam prediction increases but the recall\\ndecreases which is expected when you have high specificity and low sensitivity. \\nThe opposite occurs when I reduce the threshold, precision decreases but the recall increases. \\nAnd the scores for not spam prediction moves in the opposite direction of the spam prediction.\\n'"
       ]
      }
     ],
     "prompt_number": 230
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 9: Discuss the pro's/con's of moving the threshold away from 50%, why is/isn't this a good idea?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#your essay-style answer here\n",
      "'''\n",
      "Increasing or reducing your threshold is like moving along the ROC curve. If you are increasing the threshold\n",
      "you gain more specificity but reduced sensitivity, and vice versa. You can have a high specificity but having a low\n",
      "sensitivity is not a good thing. Same with a high sensitivity and low specificity. \n",
      "The threshold you choose depends on the particular problem you are solving, depending mostly on the effects of a wrong prediction.\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 178,
       "text": [
        "'\\nIncreasing or reducing your threshold is like moving along the ROC curve. If you are increasing the threshold\\nyou gain more specificity but reduced sensitivity, and vice versa. You can have a high specificity but having a low\\nsensitivity is not a good thing. Same with a high sensitivity and low specificity. \\nThe threshold you choose depends on the particular problem you are solving.\\n'"
       ]
      }
     ],
     "prompt_number": 178
    }
   ],
   "metadata": {}
  }
 ]
}