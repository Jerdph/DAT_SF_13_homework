{
 "metadata": {
  "name": "",
  "signature": "sha256:4533820e0238ff4e4baee7f6931eecb51823dbf043d9eeafded92fb6d3009378"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GA Data Science 13 \n",
      "\n",
      "### ROC Curves, Imbalanced Classes\n",
      "\n",
      "In this lab/lecture, we will learn about imbalanced classes and ROC curves, a more sophisticated measure of classifier performance than outputing just an error rate.\n",
      "\n",
      "ROC curves work in the context of Binary classification. And they capture the tradeoff between the True Positive and False positive percentages. A perfect classifier would have 100% true positive percentage, meaning that it classified all the elements in the positive class as being positive and it made no errors in misclassifying the elements in the negative class as being positive. \n",
      "\n",
      "True Positive Percentage = (# True Positives) / (# All Positives)\n",
      "\n",
      "False Positive Percentage = (# False Positives) / (# All Negatives)\n",
      "\n",
      "Although this is possible, in reality, as you increase the true positive percentage, you also increase the false positive percentage. The ROC curve captures this relationship. \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Logistic Regression on Titanic Dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import classification_report"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import data\n",
      "data_orig = pd.read_csv('titanic-train.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for the purposes of this example, will make the minority class, survived, much smaller \n",
      "#than the majority class. We will make the survived class have only 100 entries\n",
      "\n",
      "data_survived = data_orig[data_orig.Survived == 1]\n",
      "data_passed = data_orig[data_orig.Survived == 0]\n",
      "tmp = [data_survived[:100], data_passed]\n",
      "data = pd.concat(tmp)\n",
      "print data.info()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 649 entries, 1 to 890\n",
        "Data columns (total 12 columns):\n",
        "PassengerId    649 non-null int64\n",
        "Survived       649 non-null int64\n",
        "Pclass         649 non-null int64\n",
        "Name           649 non-null object\n",
        "Sex            649 non-null object\n",
        "Age            505 non-null float64\n",
        "SibSp          649 non-null int64\n",
        "Parch          649 non-null int64\n",
        "Ticket         649 non-null object\n",
        "Fare           649 non-null float64\n",
        "Cabin          100 non-null object\n",
        "Embarked       648 non-null object\n",
        "dtypes: float64(2), int64(5), object(5)None\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#fill na, define features and target numpy arrays\n",
      "numerical_features = data.get(['Fare', 'Pclass', 'Age'])\n",
      "features_array = numerical_features.fillna(numerical_features.dropna().median()).values\n",
      "target = data.Survived.values\n",
      "\n",
      "# train test split\n",
      "features_train, features_test, target_train, target_test = train_test_split(features_array, target, test_size=0.20, random_state=0)\n",
      "\n",
      "# train logistic regression, evaluate on test\n",
      "lr = LogisticRegression(C=1)\n",
      "lr.fit(features_train, target_train)\n",
      "    \n",
      "#clf = train_test(data_out)\n",
      "target_predicted = lr.predict(features_test)\n",
      "    \n",
      "#evaluate accuracy\n",
      "print(\"Train Testing Results \\n\\n\")\n",
      "\n",
      "print(classification_report(target_test, target_predicted,\n",
      "                         target_names=['not survived', 'survived']))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Testing Results \n",
        "\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "not survived       0.84      0.98      0.90       109\n",
        "    survived       0.00      0.00      0.00        21\n",
        "\n",
        " avg / total       0.70      0.82      0.76       130\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that the classifier does not do so well on the \"Survived\" Class ... "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Let's downsample the majority class to train our classifer and see if we can get better performance\n",
      "\n",
      "To do this, we will train our logistic regression classifier with downsampled data and use this trained classifier on the non-downsampled data to see if it can do a better job"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We are downsampling the majority class and training a new classifier\n",
      "\n",
      "tmp = [data_survived[:100], data_passed[:100]]\n",
      "data_ds = pd.concat(tmp)\n",
      "\n",
      "numerical_features_ds = data_ds.get(['Fare', 'Pclass', 'Age'])\n",
      "features_array_ds = numerical_features_ds.fillna(numerical_features_ds.dropna().median()).values\n",
      "target_ds = data_ds.Survived.values\n",
      "\n",
      "#train test split\n",
      "features_train_ds, features_test_ds, target_train_ds, target_test_ds = train_test_split(features_array_ds, target_ds, test_size=0.20, random_state=0)\n",
      "\n",
      "# train logistic regression, evaluate on test\n",
      "lr_ds = LogisticRegression(C=1)\n",
      "lr_ds.fit(features_train_ds, target_train_ds)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Now we are taking this classifier trained on downsampled data and seeing if it performs better with the full dataset. Note that we are testing the classifier \"lr_ds\" with 'features_test'\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_predicted_ds = lr_ds.predict(features_test)\n",
      "    \n",
      "#evaluate accuracy\n",
      "print(\"Train Testing Results With Downsampling the majority class \\n\\n\")\n",
      "\n",
      "print(classification_report(target_test, target_predicted_ds,\n",
      "                         target_names=['not survived', 'survived']))\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Testing Results With Downsampling the majority class \n",
        "\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "not survived       0.86      0.72      0.78       109\n",
        "    survived       0.21      0.38      0.27        21\n",
        "\n",
        " avg / total       0.75      0.66      0.70       130\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that the classifier does much better on the \"Survived\" class and a little worse on the \"Not Survived\" Class"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Instead of downsampling the majority class, let's upsample the minority class"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = [data_survived, data_survived, data_passed]\n",
      "data_us = pd.concat(tmp)\n",
      "\n",
      "numerical_features_us = data_us.get(['Fare', 'Pclass', 'Age'])\n",
      "features_array_us = numerical_features_us.fillna(numerical_features_us.dropna().median()).values\n",
      "target_us = data_us.Survived.values\n",
      "\n",
      "#train test split\n",
      "features_train_us, features_test_us, target_train_us, target_test_us = train_test_split(features_array_us, target_us, test_size=0.20, random_state=0)\n",
      "\n",
      "# train logistic regression, evaluate on test\n",
      "lr_us = LogisticRegression(C=1)\n",
      "lr_us.fit(features_train_us, target_train_us)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Now we are taking this classifier trained on downsampled data and seeing if it performs better with the full dataset. Note that we are testing the classifier \"lr_us\" with 'features_test'\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_predicted_us = lr_us.predict(features_test)\n",
      "    \n",
      "#evaluate accuracy\n",
      "print(\"Train Testing Results With Downsampling the majority class and Upsampling the Minority Class \\n\\n\")\n",
      "\n",
      "print(classification_report(target_test, target_predicted_us,\n",
      "                         target_names=['not survived', 'survived']))\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Testing Results With Downsampling the majority class and Upsampling the Minority Class \n",
        "\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "not survived       0.86      0.66      0.75       109\n",
        "    survived       0.20      0.43      0.27        21\n",
        "\n",
        " avg / total       0.75      0.62      0.67       130\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Model evaluation and interpretation, ROC"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Logistic Regression is a probabilistic models: instead of just predicting a binary outcome (survived or not) given the input features it can also estimates the probability of the outcome given the input features using the `predict_proba` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "proba_lr_ds = lr_ds.predict_proba(features_test)\n",
      "\n",
      "print proba_lr_ds[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.53003519  0.46996481]\n",
        " [ 0.57799702  0.42200298]\n",
        " [ 0.56418399  0.43581601]\n",
        " [ 0.76572377  0.23427623]\n",
        " [ 0.62389213  0.37610787]]\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By default the decision threshold is 0.5: if we vary the decision threshold from 0 to 1 we could generate a family of binary classifier models that address all the possible trade offs between false positive and false negative prediction errors.\n",
      "\n",
      "We can summarize the performance of a binary classifier for all the possible thresholds by plotting the ROC curve and quantifying the Area under the ROC curve:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "from sklearn.metrics import auc\n",
      "\n",
      "def plot_roc_curve(target_test, target_predicted_proba, this_label):\n",
      "    fpr, tpr, thresholds = roc_curve(target_test, target_predicted_proba[:, 1])\n",
      "    \n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    # Plot ROC curve\n",
      "    plt.plot(fpr, tpr, label= this_label + ', ROC Area = %0.3f' % roc_auc)\n",
      "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.0])\n",
      "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
      "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
      "    plt.title('ROC')\n",
      "    plt.legend(loc=\"lower right\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_roc_curve(target_test, proba_lr, \"DS\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10a0cb650>"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Another Strategy ... Adjusting Class Weights \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We'll use the datasets before we downsample or upsample ... \n",
      "#Remember that our classifier did very poorly in classifying the minority class here\n",
      "features_train, features_test, target_train, target_test = train_test_split(features_array, target, test_size=0.20, random_state=0)\n",
      "\n",
      "# train logistic regression, evaluate on test, set class_weight = 'auto'\n",
      "lr = LogisticRegression(C=1, class_weight='auto')\n",
      "lr.fit(features_train, target_train)\n",
      "    \n",
      "#clf = train_test(data_out)\n",
      "target_predicted = lr.predict(features_test)\n",
      "    \n",
      "#evaluate accuracy\n",
      "print(\"Train Testing Results \\n\\n\")\n",
      "\n",
      "print(classification_report(target_test, target_predicted,\n",
      "                         target_names=['not survived', 'survived']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train Testing Results \n",
        "\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "not survived       0.84      0.76      0.80       109\n",
        "    survived       0.16      0.24      0.19        21\n",
        "\n",
        " avg / total       0.73      0.68      0.70       130\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Much better result without having to oversample or undersample"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}